{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cAdXCpNn3pv3",
   "metadata": {
    "cell_id": "00017-3b51644a-c255-4a6a-84d8-91f2e0044198",
    "deepnote_cell_type": "markdown",
    "id": "cAdXCpNn3pv3"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Integración de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_path = os.path.abspath('..')\n",
    "sys.path.insert(1, project_path)\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.features.preprocessing import preprocessing, custom_features, boc_some_values, boc_many_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea principal\n",
    "\n",
    "- Tener un pipeline básico para cada una de las tareas\n",
    "- Dejar pre-procesamiento\n",
    "- Compatibilidad con output de modelo de lenguaje\n",
    "- Elegir mejor manera de incluir modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('Pre-procesamiento',preprocessing),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time_ns()\n",
    "    s = now - since\n",
    "    return s*10**(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP\n",
      "Time elapsed for training: 6.620332166000001 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 0.043536191 seconds\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.31      0.28      0.29       497\n",
      "Mostly Positive       0.28      0.29      0.28       512\n",
      "       Negative       0.46      0.33      0.38       387\n",
      "       Positive       0.33      0.42      0.37       610\n",
      "  Very Positive       0.41      0.36      0.38       359\n",
      "\n",
      "       accuracy                           0.34      2365\n",
      "      macro avg       0.36      0.34      0.34      2365\n",
      "   weighted avg       0.35      0.34      0.34      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP\")\n",
    "start = time.time_ns()\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe.predict(X_eval)\n",
    "\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versión logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LogitsEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_logits = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',LogitsEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_logits = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_logits),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con logit embeddings\n",
      "\n",
      "Time elapsed for training: 131.765849573 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 51.816425677000005 seconds\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.27      0.37      0.31       497\n",
      "Mostly Positive       0.26      0.21      0.23       512\n",
      "       Negative       0.45      0.35      0.39       387\n",
      "       Positive       0.35      0.41      0.38       610\n",
      "  Very Positive       0.42      0.32      0.36       359\n",
      "\n",
      "       accuracy                           0.33      2365\n",
      "      macro avg       0.35      0.33      0.33      2365\n",
      "   weighted avg       0.34      0.33      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con logit embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_logits.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_logits.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versión token [CLF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_tok_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente al token contextualizado\n",
    "    return cfl_output['hidden_states'][-1][0][0].detach().numpy().reshape(1,768)\n",
    "\n",
    "class CLFTokenEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: first_tok_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_CLFToken = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',CLFTokenEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_CLFToken = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_CLFToken),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con CLFToken embeddings\n",
      "\n",
      "Time elapsed for training: 141.993939402 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 56.33335626 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con CLFToken embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_CLFToken.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_CLFToken.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 min approx entre fit y predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.31      0.30       497\n",
      "Mostly Positive       0.23      0.08      0.12       512\n",
      "       Negative       0.36      0.37      0.37       387\n",
      "       Positive       0.32      0.52      0.40       610\n",
      "  Very Positive       0.38      0.27      0.32       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.32      0.31      0.30      2365\n",
      "   weighted avg       0.31      0.32      0.30      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versión promedio de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente a la suma de los vectores contextualizados\n",
    "    return cfl_output['hidden_states'][-1][0].detach().numpy().mean(axis=0).reshape(1,768)\n",
    "\n",
    "class MeanEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: mean_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_mean = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',MeanEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_mean = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_mean),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con mean embeddings\n",
      "\n",
      "Time elapsed for training: 139.731334318 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 59.623988174000004 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con mean embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_mean.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_mean.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.27      0.37      0.31       497\n",
      "Mostly Positive       0.20      0.08      0.11       512\n",
      "       Negative       0.34      0.39      0.36       387\n",
      "       Positive       0.34      0.47      0.39       610\n",
      "  Very Positive       0.39      0.21      0.27       359\n",
      "\n",
      "       accuracy                           0.31      2365\n",
      "      macro avg       0.31      0.30      0.29      2365\n",
      "   weighted avg       0.30      0.31      0.29      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-words clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "bow = CountVectorizer(\n",
    "    tokenizer= StemmerTokenizer(),\n",
    "    ngram_range=(1,2),\n",
    "    min_df = 0.05, max_df = 0.85\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('BoWText',bow,'short_description')\n",
    "])\n",
    "\n",
    "pipe_bow = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_bow),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con bag-of-words\n",
      "\n",
      "Time elapsed for training: 8.205354385 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 1.5025425110000001 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con bag-of-words\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_bow.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_bow.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.31      0.24      0.27       497\n",
      "Mostly Positive       0.29      0.17      0.21       512\n",
      "       Negative       0.43      0.41      0.42       387\n",
      "       Positive       0.32      0.52      0.39       610\n",
      "  Very Positive       0.43      0.35      0.38       359\n",
      "\n",
      "       accuracy                           0.34      2365\n",
      "      macro avg       0.35      0.34      0.34      2365\n",
      "   weighted avg       0.34      0.34      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW + logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con logit embeddings + BoW\n",
      "\n",
      "Time elapsed for training: 136.28623183300002 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 53.621551404 seconds\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.28      0.30      0.29       497\n",
      "Mostly Positive       0.26      0.17      0.21       512\n",
      "       Negative       0.38      0.48      0.42       387\n",
      "       Positive       0.35      0.41      0.38       610\n",
      "  Very Positive       0.42      0.36      0.38       359\n",
      "\n",
      "       accuracy                           0.34      2365\n",
      "      macro avg       0.34      0.34      0.34      2365\n",
      "   weighted avg       0.33      0.34      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocesisng_logits_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',LogitsEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_logits_bow = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_logits_bow),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Resultados clasificación MLP con logit embeddings + BoW\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_logits_bow.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_logits_bow.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['estimated_sells'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados regresión sin texto\n",
      "\n",
      "Time elapsed for training: 9.014024873 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 0.057883677 seconds\n",
      "\n",
      "Error cuadrático medio = 730686091203.4044\n",
      "Score R2 = 0.5924228283913218\n"
     ]
    }
   ],
   "source": [
    "pipe_reg = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Regresor',BaggingRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "print(\"Resultados regresión sin texto\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_reg.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_reg.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(\"Error cuadrático medio = {}\".format(mean_squared_error(y_eval,y_pred)))\n",
    "print(\"Score R2 = {}\".format(r2_score(y_eval,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogames-descriptions-sells\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg_bow = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_bow),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Regresor',BaggingRegressor(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados regresión con bag-of-words\n",
      "\n",
      "Time elapsed for training: 11.977677203 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 1.4346816690000002 seconds\n",
      "\n",
      "Error cuadrático medio = 824150143306.8201\n",
      "Score R2 = 0.5402885200173145\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados regresión con bag-of-words\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_reg_bow.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_reg_bow.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(\"Error cuadrático medio = {}\".format(mean_squared_error(y_eval,y_pred)))\n",
    "print(\"Score R2 = {}\".format(r2_score(y_eval,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,1)\n",
    "\n",
    "class LogitsEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new\n",
    "\n",
    "preprocesisng_logits_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',LogitsEmbedding(),'short_description')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg_logits = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_logits_reg),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "    ('Regresor',BaggingRegressor(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados regresión con logit embeddings\n",
      "\n",
      "Time elapsed for training: 129.489771709 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 52.863194716 seconds\n",
      "\n",
      "Error cuadrático medio = 784042788295.7003\n",
      "Score R2 = 0.5626604284372694\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados regresión con logit embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_reg_logits.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_reg_logits.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(\"Error cuadrático medio = {}\".format(mean_squared_error(y_eval,y_pred)))\n",
    "print(\"Score R2 = {}\".format(r2_score(y_eval,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 908859779499.0122\n",
      "Score R2 = 0.49303743046892634\n"
     ]
    }
   ],
   "source": [
    "print(\"Error cuadrático medio = {}\".format(mean_squared_error(y_eval,y_pred)))\n",
    "print(\"Score R2 = {}\".format(r2_score(y_eval,y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un desafío en la tarea es como integrar las columnas de texto. El texto es usualmente una variable complicada de modelar. Por un lado en el curso vimos como usar modelos basados en bag-of-words. Esto consiste en contar las palabras (y eventualmente conjuntos cortos de palabras, llámese n-gramas) y generar columnas categóricas que representen la presencia o no de un palabra o n-grama en el documento en cuestión.\n",
    "\n",
    "Hemos integrado este tipo de columnas en nuestro modelamiento. Sin embargo, una familia de modelos que es típicamente usada en tiempos recientes son los llamados modelos de lenguaje. Más precisamente, aquellos basados en la arquitectura de red neuronal \"Transformer\" han tenido un éxito rotundo resolviendo varias tareas de NLP. Usaremos también este modelo para resolver nuestra tarea.\n",
    "\n",
    "En cualquier caso debemos tener en cuenta que la descripción del juego no tendría que ser a priori una variable importante en la predicción del éxito de este. Predecir si un juego será bueno o no es difícil para un ser humano, que puede decidir si un juego es atractivo o no para jugarlo, sin embargo sus ventas y sobretodo sus calificaciones dependerán de la experiencia de juego, que puede no estar reflejada en la descripción.\n",
    "\n",
    "Dicho esto, hemos ajustado un modelo de lenguaje pre-entrenado para que predica las calificaciones de este. Esto se realizó usando la biblioteca de HuggingFace transformers. En particular usamos el modelo DistilBERT, que es una variante del exitoso modelo de Google BERT.\n",
    "\n",
    "Un modelo de lenguaje como este nos entrega varias maneras de codificar texto. Por un lado tenemos vectores contextualizados por cada token en la secuencia. Esto nos permite tener el promedio de estos vectores como representación de la secuencia. También podemos usar el vector contextualizado del token especial [CLF], que es típicamente usado para las tareas de clasificación.\n",
    "\n",
    "Lamentablemente estás opciones son costosas puesto que el espacio de representaciones de BERT es de alta dimensionalidad (785 en nuestro caso). Esto le agrega complejidad quizás excesiva a nuestros modelos. Es por esto que también consideramos como representación las probabilidades para cada categoría que predice nuesteo modelo. Llamamos a esto logits embeddings.\n",
    "\n",
    "Experimentos simples y de inspección confirman que las opción logit es más conveniente que usar vectores de promedio y [CLF]. Además, la opción de usar bag-of-words igualmente es competitiva. Finalmente usamos también la opción de no usar texto. Son estas tres opciones (logits, bow y sin-texto) que integraremos a nuestro gridsearch. Cabe señalar que se intentó hacer lo mismo para la tarea de regresión pero los resultados no son satisfactorios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
