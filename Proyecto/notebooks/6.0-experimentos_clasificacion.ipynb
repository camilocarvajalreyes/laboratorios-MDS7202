{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5L8iIkYD3pv3",
   "metadata": {
    "cell_id": "00024-97baa921-e984-460f-8c3f-2653d51eaba6",
    "deepnote_cell_type": "markdown",
    "id": "5L8iIkYD3pv3"
   },
   "source": [
    "---\n",
    "\n",
    "## 8.1 Experimentación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a71-8i63pv3",
   "metadata": {
    "cell_id": "00027-cc2df460-abd0-4a1e-a3a3-60b37dee8cd0",
    "deepnote_cell_type": "code",
    "id": "0a71-8i63pv3"
   },
   "source": [
    "Se realizaron, para aquellos modelos con mejores resultados en la fase de gridsearch, una validación cruzada. Esta consistió en el uso del método CrossValidation de sklearn, lo cual se realizó con el conjunto entero de datos.\n",
    "\n",
    "Recordemos que el método particiona el conjunto en 5 partes (valor por defecto que mantuvimos). Entrena el modelo con 4 partes de 5 y testea con el quinto restante. Esto genera cinco resultados diferentes, que es lo que analizamos.\n",
    "\n",
    "Hemos así testeado los métodos por separado, pero también agregamos un estimador de voto en casa caso, reuniendo el poder de predicción de cada uno de los métodos utilizados. Esto resultó de importancia para los buenos resultados que obtuvimos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_path = os.path.abspath('..')\n",
    "sys.path.insert(1, project_path)\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from preprocessing import Nothing, CategoriesTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "\n",
    "from src.features.preprocessing import boc_many_values, boc_some_values, Nothing, CategoriesTokenizer, custom_features, preprocessing_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output\n",
    "\n",
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrar_bert_logits(df_in):\n",
    "    df = df_in.copy(deep=True)\n",
    "\n",
    "    embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "    bert_logits = np.concatenate(df['short_description'].apply(embed).to_numpy())  # .reshape(100,3)\n",
    "\n",
    "    df[['bert1','bert2','bert3','bert4','bert5']] = pd.DataFrame(bert_logits, index= df.index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = integrar_bert_logits(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = custom_features(df_train)\n",
    "# X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(clf):\n",
    "    pipeline = Pipeline(\n",
    "        [(\"procesamiento\", preprocessing_bert),\n",
    "        (\"selector\", SelectPercentile(f_classif, percentile=95)),\n",
    "        (\"classifier\", clf)]\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrador de GridSearch (clasificación)\n",
    "\n",
    "**Candidatos**:\n",
    "- SVCLineal\n",
    "- KNeighbors\n",
    "- RandomForest\n",
    "- MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores_exp = [\n",
    "    LinearSVC(random_state=0),\n",
    "    KNeighborsClassifier(weights='distance'),\n",
    "    RandomForestClassifier(n_estimators=250, random_state=0),\n",
    "    MLPClassifier(hidden_layer_sizes=(200,), learning_rate_init=0.01, solver='sgd',random_state = 0),\n",
    "    VotingClassifier(estimators=[\n",
    "        ('SVC', LinearSVC(random_state=0)),\n",
    "        ('KN', KNeighborsClassifier(weights='distance')),\n",
    "        ('RF', RandomForestClassifier(n_estimators=250, random_state=0)),\n",
    "        ('MLP', MLPClassifier(hidden_layer_sizes=(200,), learning_rate_init=0.01, solver='sgd',random_state = 0))\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "results_cv = {}\n",
    "\n",
    "for classif in clasificadores_exp:\n",
    "    pipe = make_pipeline(reg)\n",
    "    score = cross_val_score(pipe,df_train, df_train['rating'],scoring='f1_weighted')\n",
    "    results_cv[type(reg).__name__] = score\n",
    "    # print(\"CV SCORE {}: {}\".format(type(reg).__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV SCORE LinearSVC: [0.36057687 0.34802132 0.37176183 0.35326648 0.34257792]\n",
      "CV SCORE KNeighborsClassifier: [0.29278178 0.28670371 0.31304605 0.31712508 0.30444146]\n",
      "CV SCORE RandomForestClassifier: [0.35857368 0.36460172 0.37187043 0.35138941 0.35626242]\n",
      "CV SCORE MLPClassifier: [0.36815039 0.35760368 0.37994783 0.37399761 0.35189534]\n",
      "CV SCORE VotingClassifier: [0.36662592 0.36160182 0.37349064 0.37553451 0.35211995]\n"
     ]
    }
   ],
   "source": [
    "for classif in results_cv.keys():\n",
    "    print(\"CV SCORE {}: {}\".format(classif,results_cv[classif]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo | Fold 1 | Fold 2 | Fold 3 | Fold 4 | Fold 5 | **Promedio** |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **LinearSVC** | 0.36057687 | 0.34802132 | 0.37176183 | 0.35326648 | 0.34257792 | **0.3551** |\n",
    "| **KNeighborsClassifier** | 0.29278178 | 0.28670371 | 0.31304605 | 0.31712508 | 0.30444146 | **0.3027** |\n",
    "| **RandomForestClassifier** | 0.35857368 | 0.36460172 | 0.37187043 | 0.35138941 | 0.35626242 | **0.3604** |\n",
    "| **MLPClassifier** | 0.36815039 | 0.35760368 | 0.37994783 | 0.37399761 | 0.35189534 | **0.3662** |\n",
    "| **VotingClassifier** | 0.36662592 | 0.36160182 | 0.37349064 | 0.37553451 | 0.35211995 | **0.3658** |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos muestran una relativa estabilidad en los distintos folds. Esto nos asegura la estabilidad de nuestros modelos. El modelo con mejor resultado fue el perceptrón multi-capa, con una ganancia marginal por sobre el estimador de voto al comparar el promedio de los resultados. Sin embargo, al utilizar este estimador para la predicción en codalab se obtuvo un punto porcentual menos de score f1 con respecto al voto de varios modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
