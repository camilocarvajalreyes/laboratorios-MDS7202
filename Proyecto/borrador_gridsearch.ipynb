{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrador de GridSearch (Clasificación)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-gridsearch: eligiendo que modelos usar\n",
    "\n",
    "**Candidatos**\n",
    "- Linear SVC (baseline)\n",
    "- SVC (no lineal)\n",
    "- KNeighbours\n",
    "- RandomForestClassifier\n",
    "- DecisionTreeClassifier\n",
    "- MLP (red-neuronal de sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import train_and_evaluate_clf, custom_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time_ns()\n",
    "    s = now - since\n",
    "    return s*10**(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación LinearSVC\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.30      0.31      0.30       497\n",
      "Mostly Positive       0.26      0.23      0.24       512\n",
      "       Negative       0.42      0.33      0.37       387\n",
      "       Positive       0.33      0.44      0.38       610\n",
      "  Very Positive       0.41      0.30      0.35       359\n",
      "\n",
      "       accuracy                           0.33      2365\n",
      "      macro avg       0.34      0.32      0.33      2365\n",
      "   weighted avg       0.33      0.33      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "baseline = LinearSVC(random_state=0,max_iter=10000)\n",
    "train_and_evaluate_clf(baseline,X_train,y_train,X_eval,y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clasificadores = [\n",
    "    SVC(random_state=0),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    MLPClassifier(early_stopping =True,max_iter = 100, random_state=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación SVC\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.33      0.28      0.30       497\n",
      "Mostly Positive       0.27      0.15      0.20       512\n",
      "       Negative       0.38      0.33      0.35       387\n",
      "       Positive       0.32      0.65      0.43       610\n",
      "  Very Positive       0.58      0.14      0.23       359\n",
      "\n",
      "       accuracy                           0.34      2365\n",
      "      macro avg       0.38      0.31      0.30      2365\n",
      "   weighted avg       0.36      0.34      0.31      2365\n",
      "\n",
      "Time elapsed for SVC method: 5.831981818 seconds\n",
      "\n",
      "Resultados clasificación KNeighborsClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.27      0.35      0.31       497\n",
      "Mostly Positive       0.25      0.32      0.28       512\n",
      "       Negative       0.36      0.22      0.28       387\n",
      "       Positive       0.32      0.36      0.34       610\n",
      "  Very Positive       0.36      0.14      0.20       359\n",
      "\n",
      "       accuracy                           0.29      2365\n",
      "      macro avg       0.31      0.28      0.28      2365\n",
      "   weighted avg       0.31      0.29      0.29      2365\n",
      "\n",
      "Time elapsed for KNeighborsClassifier method: 0.704947881 seconds\n",
      "\n",
      "Resultados clasificación RandomForestClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.31      0.29      0.30       497\n",
      "Mostly Positive       0.25      0.22      0.24       512\n",
      "       Negative       0.45      0.34      0.39       387\n",
      "       Positive       0.33      0.52      0.40       610\n",
      "  Very Positive       0.46      0.23      0.31       359\n",
      "\n",
      "       accuracy                           0.33      2365\n",
      "      macro avg       0.36      0.32      0.33      2365\n",
      "   weighted avg       0.35      0.33      0.33      2365\n",
      "\n",
      "Time elapsed for RandomForestClassifier method: 6.576451607 seconds\n",
      "\n",
      "Resultados clasificación DecisionTreeClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.25      0.26      0.25       497\n",
      "Mostly Positive       0.24      0.23      0.23       512\n",
      "       Negative       0.33      0.32      0.32       387\n",
      "       Positive       0.29      0.30      0.29       610\n",
      "  Very Positive       0.29      0.28      0.29       359\n",
      "\n",
      "       accuracy                           0.28      2365\n",
      "      macro avg       0.28      0.28      0.28      2365\n",
      "   weighted avg       0.28      0.28      0.28      2365\n",
      "\n",
      "Time elapsed for DecisionTreeClassifier method: 0.545165452 seconds\n",
      "\n",
      "Resultados clasificación MLPClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.27      0.32      0.29       497\n",
      "Mostly Positive       0.27      0.27      0.27       512\n",
      "       Negative       0.44      0.27      0.33       387\n",
      "       Positive       0.33      0.38      0.35       610\n",
      "  Very Positive       0.41      0.36      0.38       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.34      0.32      0.33      2365\n",
      "   weighted avg       0.33      0.32      0.32      2365\n",
      "\n",
      "Time elapsed for MLPClassifier method: 7.5314552610000005 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in clasificadores:\n",
    "    start = time.time_ns()\n",
    "    train_and_evaluate_clf(clf,X_train,y_train,X_eval,y_eval)\n",
    "    print(\"Time elapsed for {} method: {} seconds\\n\".format(type(clf).__name__,timeSince(start)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrador de GridSearch (regresión)\n",
    "\n",
    "**Candidatos**:\n",
    "- Lasso\n",
    "- ElasticNet\n",
    "- Ridge\n",
    "- SVR Lineal\n",
    "- SVR polinomial\n",
    "- SVR RBF\n",
    "- Bagging\n",
    "- DecisionTree\n",
    "- RandomForest\n",
    "- GradientBoosting\n",
    "- ExtraTreesRegressor\n",
    "- AdaBoostRegressor\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, ElasticNet, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, HistGradientBoostingRegressor, VotingRegressor, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresores = [\n",
    "    # Lasso(random_state=0),\n",
    "    ElasticNet(random_state=0),\n",
    "    Ridge(random_state=0),\n",
    "    SVR(kernel='linear'),\n",
    "    SVR(kernel='poly'),\n",
    "    SVR(kernel='rbf'),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor(random_state=0),\n",
    "    BaggingRegressor(random_state=0),\n",
    "    GradientBoostingRegressor(random_state=0),\n",
    "    RandomForestRegressor(random_state=0),\n",
    "    ExtraTreesRegressor(random_state=0),\n",
    "    AdaBoostRegressor(random_state=0),\n",
    "    HistGradientBoostingRegressor(random_state=0),\n",
    "    # VotingRegressor(estimators=[])\n",
    "    # StackingRegressor(estimators=[])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['estimated_sells'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados regresión ElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1671862250468.4912\n",
      "Score R2 = 0.06743416144268821\n",
      "Time elapsed for ElasticNet method: 3.20046093 seconds\n",
      "\n",
      "Resultados regresión Ridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1671714745834.077\n",
      "Score R2 = 0.0675164396226311\n",
      "Time elapsed for Ridge method: 2.1293839510000003 seconds\n",
      "\n",
      "Resultados regresión SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1826399676596.286\n",
      "Score R2 = -0.018766914241011623\n",
      "Time elapsed for SVR method: 7.227484970000001 seconds\n",
      "\n",
      "Resultados regresión SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1828406595677.1208\n",
      "Score R2 = -0.01988637499503687\n",
      "Time elapsed for SVR method: 7.291538781000001 seconds\n",
      "\n",
      "Resultados regresión SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1828419560737.7725\n",
      "Score R2 = -0.01989360691420683\n",
      "Time elapsed for SVR method: 7.567372447 seconds\n",
      "\n",
      "Resultados regresión KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 1618006553204.5938\n",
      "Score R2 = 0.09747490401338832\n",
      "Time elapsed for KNeighborsRegressor method: 2.641175048 seconds\n",
      "\n",
      "Resultados regresión DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 4151985370512.4297\n",
      "Score R2 = -1.3159801099908788\n",
      "Time elapsed for DecisionTreeRegressor method: 3.583755426 seconds\n",
      "\n",
      "Resultados regresión BaggingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 849260002373.9049\n",
      "Score R2 = 0.5262822244804723\n",
      "Time elapsed for BaggingRegressor method: 10.100534665000001 seconds\n",
      "\n",
      "Resultados regresión GradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 873959181886.295\n",
      "Score R2 = 0.5125050062633643\n",
      "Time elapsed for GradientBoostingRegressor method: 3.123649127 seconds\n",
      "\n",
      "Resultados regresión RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 848514036795.0035\n",
      "Score R2 = 0.5266983245601458\n",
      "Time elapsed for RandomForestRegressor method: 78.73350649700001 seconds\n",
      "\n",
      "Resultados regresión ExtraTreesRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 3731250678040.489\n",
      "Score R2 = -1.081294027937588\n",
      "Time elapsed for ExtraTreesRegressor method: 120.09851663100001 seconds\n",
      "\n",
      "Resultados regresión AdaBoostRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio = 4798858708829.279\n",
      "Score R2 = -1.6768064741358777\n",
      "Time elapsed for AdaBoostRegressor method: 2.9039158520000004 seconds\n",
      "\n",
      "Resultados regresión HistGradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/camilo/laboratorios-MDS7202/Proyecto/borrador_gridsearch.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/laboratorios-MDS7202/Proyecto/borrador_gridsearch.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m regresores:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/laboratorios-MDS7202/Proyecto/borrador_gridsearch.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime_ns()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/camilo/laboratorios-MDS7202/Proyecto/borrador_gridsearch.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_and_evaluate_reg(clf,X_train,y_train,X_eval,y_eval)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/laboratorios-MDS7202/Proyecto/borrador_gridsearch.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTime elapsed for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m method: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(clf)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,timeSince(start)))\n",
      "File \u001b[0;32m~/laboratorios-MDS7202/Proyecto/preprocessing.py:80\u001b[0m, in \u001b[0;36mtrain_and_evaluate_reg\u001b[0;34m(clf, X_train, y_train, X_eval, y_eval, perc)\u001b[0m\n\u001b[1;32m     78\u001b[0m pipe \u001b[39m=\u001b[39m make_pipeline(clf,preprocessisng,perc)\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResultados regresión \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(clf)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m---> 80\u001b[0m pipe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     81\u001b[0m y_pred \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mpredict(X_eval)\n\u001b[1;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError cuadrático medio = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(mean_squared_error(y_eval,y_pred)))\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:287\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m# time spent predicting X for gradient and hessians update\u001b[39;00m\n\u001b[1;32m    286\u001b[0m acc_prediction_time \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m--> 287\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, dtype\u001b[39m=\u001b[39;49m[X_DTYPE], force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    288\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_y(y)\n\u001b[1;32m    289\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/utils/validation.py:822\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(array):\n\u001b[1;32m    821\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 822\u001b[0m     array \u001b[39m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    823\u001b[0m         array,\n\u001b[1;32m    824\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    825\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    826\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    827\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    828\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    829\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    830\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[39m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[39m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     \u001b[39m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    836\u001b[0m     \u001b[39m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     \u001b[39m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m~/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/utils/validation.py:512\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    509\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m accept_sparse \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA sparse matrix was passed, but dense \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata is required. Use X.toarray() to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvert to a dense numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(accept_sparse, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(accept_sparse) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from preprocessing import train_and_evaluate_reg\n",
    "\n",
    "for clf in regresores:\n",
    "    start = time.time_ns()\n",
    "    train_and_evaluate_reg(clf,X_train,y_train,X_eval,y_eval)\n",
    "    print(\"Time elapsed for {} method: {} seconds\\n\".format(type(clf).__name__,timeSince(start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prog_cientifica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f12cc99d524414e3daaca7ff7e8e0997cdecd19277513297c62237218c0d43b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
