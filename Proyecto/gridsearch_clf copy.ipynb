{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch para clasificaci√≥n de ratings\n",
    "\n",
    "**Clasificadores a considerar**:\n",
    "- linearSVC\n",
    "- KNeighbors\n",
    "- RandomForest\n",
    "- MLP (red neuronal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF con BERT integrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output\n",
    "\n",
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrar_bert_logits(df_in):\n",
    "    df = df_in.copy(deep=True)\n",
    "\n",
    "    embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "    bert_logits = np.concatenate(df['short_description'].apply(embed).to_numpy())  # .reshape(100,3)\n",
    "\n",
    "    df[['bert1','bert2','bert3','bert4','bert5']] = pd.DataFrame(bert_logits, index= df.index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 s, sys: 207 ms, total: 5.98 s\n",
      "Wall time: 761 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = integrar_bert_logits(df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Nothing(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class CategoriesTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return doc.split(';')\n",
    "\n",
    "boc_some_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 0.05  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5%, 10%, 15%] ???\n",
    "    )\n",
    "\n",
    "\n",
    "boc_many_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 1  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5, 10, 15] ???\n",
    "    )\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "bow = CountVectorizer(\n",
    "    tokenizer= StemmerTokenizer(),\n",
    "    ngram_range=(1,2),\n",
    "    min_df = 0.05, max_df = 0.85\n",
    "    )\n",
    "\n",
    "def custom_features(dataframe_in):\n",
    "    df = dataframe_in.copy(deep=True)\n",
    "\n",
    "    df['month'] = pd.to_datetime(df['release_date']).dt.month\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.to_julian_date())\n",
    "\n",
    "    df['revenue'] = pd.Series([0 for _ in range(len(dataframe_in))])\n",
    "\n",
    "    df.loc[df.publisher.str.match('.*microsoft.*', flags=re.IGNORECASE).values, 'revenue'] = 10.260\n",
    "    df.loc[df.publisher.str.match('.*netease.*', flags=re.IGNORECASE).values, 'revenue'] = 6.668\n",
    "    df.loc[df.publisher.str.match('.*activision.*', flags=re.IGNORECASE).values, 'revenue'] = 6.388\n",
    "    df.loc[df.publisher.str.match('.*electronic.*', flags=re.IGNORECASE).values, 'revenue'] = 5.537\n",
    "    df.loc[df.publisher.str.match('.*bandai.*', flags=re.IGNORECASE).values, 'revenue'] = 3.018\n",
    "    df.loc[df.publisher.str.match('.*square.*', flags=re.IGNORECASE).values, 'revenue'] = 2.386\n",
    "    df.loc[df.publisher.str.match('.*nexon.*', flags=re.IGNORECASE).values, 'revenue'] = 2.286\n",
    "    df.loc[df.publisher.str.match('.*ubisoft.*', flags=re.IGNORECASE).values, 'revenue'] = 1.446\n",
    "    df.loc[df.publisher.str.match('.*konami.*', flags=re.IGNORECASE).values, 'revenue'] = 1.303\n",
    "    df.loc[df.publisher.str.match('.*SEGA.*').values, 'revenue'] = 1.153\n",
    "    df.loc[df.publisher.str.match('.*capcom.*', flags=re.IGNORECASE).values, 'revenue'] = 0.7673\n",
    "    df.loc[df.publisher.str.match('.*warner.*', flags=re.IGNORECASE).values, 'revenue'] = 0.7324\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessing_bert = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english','bert1','bert2','bert3','bert4','bert5'])\n",
    "])\n",
    "\n",
    "preprocessing_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english']),\n",
    "        ('BoWText',bow,'short_description')\n",
    "])\n",
    "\n",
    "preprocessing_bert_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english','bert1','bert2','bert3','bert4','bert5']),\n",
    "        ('BoWText',bow,'short_description')\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english']),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora si el gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [(\"procesamiento\", preprocessing),\n",
    "    (\"selector\", SelectPercentile(f_classif, percentile=90)),\n",
    "    (\"classifier\", LinearSVC(random_state=0))]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_SV = {\n",
    "    \"classifier\": [LinearSVC(random_state=0)],\n",
    "    \"classifier__C\":[0.01, 1., 100., 1000.],\n",
    "    \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "    \"selector__score_func\":[f_classif],\n",
    "    \"procesamiento\" : [preprocessing, preprocessing_bert, preprocessing_bert_bow, preprocessing_bow],\n",
    "    \"procesamiento__BoC-cat__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-genres__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-tags__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-dev__min_df\" : [2, 5],\n",
    "    \"procesamiento__BoC-pub__min_df\" : [2, 5],\n",
    "}\n",
    "\n",
    "gs_SV = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    grilla_SV,\n",
    "    scoring = 'f1_weighted',\n",
    "    n_jobs=5,\n",
    "    verbose = 0,\n",
    "    random_state = 0,\n",
    "    error_score = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min_resources_=50 is greater than max_resources_=14.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gs_SV\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/mds7202/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:253\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\"\"\"Run fit with all sets of parameters.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m    Instance of fitted estimator.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig \u001b[39m=\u001b[39m check_cv(\n\u001b[1;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator)\n\u001b[1;32m    251\u001b[0m )\n\u001b[0;32m--> 253\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input_parameters(\n\u001b[1;32m    254\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    255\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    256\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m    261\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/mds7202/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:191\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._check_input_parameters\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_resources_ \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m    190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_resources_ \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_resources_:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    192\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin_resources_=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_resources_\u001b[39m}\u001b[39;00m\u001b[39m is greater \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthan max_resources_=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_resources_\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_resources_ \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin_resources_=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_resources_\u001b[39m}\u001b[39;00m\u001b[39m: you might have passed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man empty dataset X.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: min_resources_=50 is greater than max_resources_=14."
     ]
    }
   ],
   "source": [
    "gs_SV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import get_scorer_names\n",
    "\n",
    "get_scorer_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo encontrado es el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_SV.best_params_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y sus m√©tricas son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_SV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificaci√≥n SupportVector\")\n",
    "gs_SV.fit(X_train, y_train)\n",
    "y_pred = gs_SV.predict(X_eval)\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados generales del gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_SV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_SV.cv_results_)['mean_test_score'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_KN = {\n",
    "    \"classifier\": [KNeighborsClassifier()],\n",
    "    \"classifier__n_neighbors\" :[3, 5, 10],\n",
    "    \"classifier__weights\" : ['uniform', 'distance'],\n",
    "    \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "    \"selector__score_func\":[f_classif],\n",
    "    \"procesamiento\" : [preprocessing, preprocessing_bert, preprocessing_bert_bow, preprocessing_bow],\n",
    "    \"procesamiento__BoC-cat__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-genres__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-tags__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-dev__min_df\" : [2, 5],\n",
    "    \"procesamiento__BoC-pub__min_df\" : [2, 5],\n",
    "}\n",
    "\n",
    "gs_KN = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    grilla_KN,\n",
    "    scoring = 'f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose = 0,\n",
    "    random_state = 0,\n",
    "    error_score = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_KN.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo encontrado es el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_KN.best_params_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y sus m√©tricas son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_KN.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificaci√≥n K-Neighbors\")\n",
    "gs_KN.fit(X_train, y_train)\n",
    "y_pred = gs_KN.predict(X_eval)\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados generales del gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_KN.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_KN.cv_results_)['mean_test_score'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_RF = {\n",
    "    \"classifier\": [RandomForestClassifier(random_state=0)],\n",
    "    \"classifier__n_estimators\" :[25, 50, 100, 250, 500],\n",
    "    \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "    \"selector__score_func\":[f_classif],\n",
    "    \"procesamiento\" : [preprocessing, preprocessing_bert, preprocessing_bert_bow, preprocessing_bow],\n",
    "    \"procesamiento__BoC-cat__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-genres__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-tags__min_df\" : [0.05, 0.075],\n",
    "    \"procesamiento__BoC-dev__min_df\" : [2, 5],\n",
    "    \"procesamiento__BoC-pub__min_df\" : [2, 5],\n",
    "}\n",
    "\n",
    "gs_RF = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    grilla_RF,\n",
    "    scoring = 'f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose = 0,\n",
    "    random_state = 0,\n",
    "    error_score = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_RF.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo encontrado es el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_RF.best_params_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y sus m√©tricas son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificaci√≥n Random Forest\")\n",
    "gs_RF.fit(X_train, y_train)\n",
    "y_pred = gs_RF.predict(X_eval)\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados generales del gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_RF.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_RF.cv_results_)['mean_test_score'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_MLP = {\n",
    "    \"classifier\": [MLPClassifier()],\n",
    "    \"classifier__hidden_layer_sizes\":[(100,),(200,),(100,50,),(200,100,)],\n",
    "    \"classifier__solver\" : ['sgd', 'adam'],\n",
    "    \"classifier__learning_rate\" : ['constant', 'invscaling', 'adaptive'],\n",
    "    \"procesamiento\" : [preprocessing, preprocessing_bert],\n",
    "    \"classifier__learning_rate_init\" : [0.1,0.01,0.001,0.0001],\n",
    "    \"selector__percentile\": [90, 95, 100],\n",
    "    \"selector__score_func\":[f_classif],\n",
    "    \"procesamiento__BoC-cat__min_df\" : [0.02],\n",
    "    \"procesamiento__BoC-genres__min_df\" : [0.02],\n",
    "    \"procesamiento__BoC-tags__min_df\" : [0.02],\n",
    "    \"procesamiento__BoC-dev__min_df\" : [1],\n",
    "    \"procesamiento__BoC-pub__min_df\" : [1],\n",
    "}\n",
    "\n",
    "gs_MLP = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    grilla_MLP,\n",
    "    scoring = 'f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose = 0,\n",
    "    random_state = 0,\n",
    "    error_score = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo encontrado es el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_MLP.best_params_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y sus m√©tricas son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_MLP.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificaci√≥n MLP\")\n",
    "gs_MLP.fit(X_train, y_train)\n",
    "y_pred = gs_MLP.predict(X_eval)\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados generales del gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_MLP.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_MLP.cv_results_)['mean_test_score'].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds7202",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b77b40b4c89a5af4082a4a0fab27f52d352466deb9a4e0b57dd9e6316e272f45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
