{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrador baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "- tener un pipeline básico para cada una de las tareas\n",
    "- dijar pre-procesamiento\n",
    "- compatibilidad con output de modelo de lenguaje\n",
    "- elegir mejor manera de incluir modelo de lenguaje"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columnas con categorías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CategoriesTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return doc.split(';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versión de vectorizador es para columnas con pocas categorías posibles (<1k):\n",
    "- platforms (3 valores posibles)\n",
    "- categories (29 valores posibles)\n",
    "- genres (26 valores posibles)\n",
    "- tags (306 valores posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_some_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 0.05  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5%, 10%, 15%] ???\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta otra versión es para developers y publishers (5617 y 3961 valores posibles respectivamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_many_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 1  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5, 10, 15] ???\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juntando todo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "\n",
    "\n",
    "preprocesisng = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "svm_lineal = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng),\n",
    "    ('Clasificador',LinearSVC(random_state=0,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_pickle('train.pickle')\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación SVM lineal\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.30      0.30      0.30       497\n",
      "Mostly Positive       0.26      0.21      0.23       512\n",
      "       Negative       0.40      0.40      0.40       387\n",
      "       Positive       0.32      0.40      0.36       610\n",
      "  Very Positive       0.40      0.36      0.38       359\n",
      "\n",
      "       accuracy                           0.33      2365\n",
      "      macro avg       0.34      0.33      0.33      2365\n",
      "   weighted avg       0.33      0.33      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificación SVM lineal\")\n",
    "svm_lineal.fit(X_train, y_train)\n",
    "y_svm = svm_lineal.predict(X_eval)\n",
    "print(classification_report(y_eval,y_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregando embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LogitsEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_logits = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',LogitsEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "svm_lineal_logits = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_logits),\n",
    "    ('Clasificador',LinearSVC(random_state=0,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación SVM lineal con logit embeddings\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.28      0.28       497\n",
      "Mostly Positive       0.26      0.22      0.24       512\n",
      "       Negative       0.39      0.40      0.40       387\n",
      "       Positive       0.33      0.37      0.35       610\n",
      "  Very Positive       0.35      0.35      0.35       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.32      0.32      0.32      2365\n",
      "   weighted avg       0.32      0.32      0.32      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación SVM lineal con logit embeddings\")\n",
    "svm_lineal_logits.fit(X_train, y_train)\n",
    "y_svm = svm_lineal_logits.predict(X_eval)\n",
    "print(classification_report(y_eval,y_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión token [CLF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_tok_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente al token contextualizado\n",
    "    return cfl_output['hidden_states'][-1][0][0].detach().numpy().reshape(1,768)\n",
    "\n",
    "class CLFTokenEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: first_tok_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_CLFToken = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',CLFTokenEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "svm_lineal_CLFToken = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_CLFToken),\n",
    "    ('Clasificador',LinearSVC(random_state=0,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación SVM lineal con logit embeddings\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.28      0.28       497\n",
      "Mostly Positive       0.25      0.26      0.26       512\n",
      "       Negative       0.41      0.40      0.40       387\n",
      "       Positive       0.31      0.33      0.32       610\n",
      "  Very Positive       0.32      0.30      0.31       359\n",
      "\n",
      "       accuracy                           0.31      2365\n",
      "      macro avg       0.32      0.31      0.32      2365\n",
      "   weighted avg       0.31      0.31      0.31      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación SVM lineal con logit embeddings\")\n",
    "svm_lineal_CLFToken.fit(X_train, y_train)\n",
    "y_svm = svm_lineal_CLFToken.predict(X_eval)\n",
    "print(classification_report(y_eval,y_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión promedio de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente a la suma de los vectores contextualizados\n",
    "    return cfl_output['hidden_states'][-1][0].detach().numpy().mean(axis=0).reshape(1,768)\n",
    "\n",
    "class MeanEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: mean_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_mean = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',MeanEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "svm_lineal_mean = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_mean),\n",
    "    ('Clasificador',LinearSVC(random_state=0,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultados clasificación SVM lineal con logit embeddings\")\n",
    "svm_lineal_mean.fit(X_train, y_train)\n",
    "y_svm = svm_lineal_mean.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.28      0.27      0.27       497\n",
      "Mostly Positive       0.24      0.24      0.24       512\n",
      "       Negative       0.37      0.33      0.34       387\n",
      "       Positive       0.30      0.33      0.32       610\n",
      "  Very Positive       0.34      0.34      0.34       359\n",
      "\n",
      "       accuracy                           0.30      2365\n",
      "      macro avg       0.31      0.30      0.30      2365\n",
      "   weighted avg       0.30      0.30      0.30      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del modelo de lenguaje sin otras features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def eval_text(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return np.argmax(scores), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lm = []\n",
    "label_names = ['Negative', 'Mixed', 'Mostly Positive', 'Positive', 'Very Positive']\n",
    "# label_names = ['Very Positive','Positive' , 'Mostly Positive', 'Mixed','Negative' ]\n",
    "\n",
    "for texto in X_eval['short_description']:\n",
    "    label, _ = eval_text(texto)\n",
    "    y_lm.append(label_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/camilo/miniconda3/envs/prog_cientifica/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_eval, y_lm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "bow = CountVectorizer(\n",
    "    tokenizer= StemmerTokenizer(),\n",
    "    ngram_range=(1,2),\n",
    "    min_df = 0.05, max_df = 0.85\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('BoWText',bow,'short_description')\n",
    "])\n",
    "\n",
    "svm_lineal_bow = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_bow),\n",
    "    ('Clasificador',LinearSVC(random_state=0,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación SVM lineal con logit embeddings\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.27      0.28       497\n",
      "Mostly Positive       0.25      0.23      0.24       512\n",
      "       Negative       0.40      0.39      0.40       387\n",
      "       Positive       0.33      0.38      0.35       610\n",
      "  Very Positive       0.39      0.36      0.38       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.33      0.33      0.33      2365\n",
      "   weighted avg       0.32      0.32      0.32      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación SVM lineal con bag-of-words\")\n",
    "svm_lineal_bow.fit(X_train, y_train)\n",
    "y_svm = svm_lineal_bow.predict(X_eval)\n",
    "print(classification_report(y_eval,y_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['estimated_sells'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_lineal = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng),\n",
    "    ('Regresor',SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_lineal.fit(X_train, y_train)\n",
    "y_svm = svr_lineal.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados regresión SVM lineal\n",
      "Error cuadrático medio = 1828414958387.0896\n",
      "Score R2 = -0.019891039720035808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(\"Resultados regresión SVM lineal\")\n",
    "print(\"Error cuadrático medio = {}\".format(mean_squared_error(y_eval,y_svm)))\n",
    "print(\"Score R2 = {}\".format(r2_score(y_eval,y_svm)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
