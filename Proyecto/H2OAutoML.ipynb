{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "\"\"\"# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"response\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\"\"\"\n",
    "\n",
    "# Start the H2O cluster (locally)\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from preprocessing import Nothing, CategoriesTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class Nothing(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class CategoriesTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return doc.split(';')\n",
    "\n",
    "boc_some_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 0.05\n",
    "    )\n",
    "\n",
    "\n",
    "boc_many_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 1\n",
    "    )\n",
    "\n",
    "\n",
    "def custom_features(dataframe_in):\n",
    "    df = dataframe_in.copy(deep=True)\n",
    "\n",
    "    df['month'] = pd.to_datetime(df['release_date']).dt.month\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.to_julian_date())\n",
    "\n",
    "    df['revenue'] = pd.Series([0 for _ in range(len(dataframe_in))])\n",
    "\n",
    "    df.loc[df.publisher.str.match('.*microsoft.*', flags=re.IGNORECASE).values, 'revenue'] = 10.260\n",
    "    df.loc[df.publisher.str.match('.*netease.*', flags=re.IGNORECASE).values, 'revenue'] = 6.668\n",
    "    df.loc[df.publisher.str.match('.*activision.*', flags=re.IGNORECASE).values, 'revenue'] = 6.388\n",
    "    df.loc[df.publisher.str.match('.*electronic.*', flags=re.IGNORECASE).values, 'revenue'] = 5.537\n",
    "    df.loc[df.publisher.str.match('.*bandai.*', flags=re.IGNORECASE).values, 'revenue'] = 3.018\n",
    "    df.loc[df.publisher.str.match('.*square.*', flags=re.IGNORECASE).values, 'revenue'] = 2.386\n",
    "    df.loc[df.publisher.str.match('.*nexon.*', flags=re.IGNORECASE).values, 'revenue'] = 2.286\n",
    "    df.loc[df.publisher.str.match('.*ubisoft.*', flags=re.IGNORECASE).values, 'revenue'] = 1.446\n",
    "    df.loc[df.publisher.str.match('.*konami.*', flags=re.IGNORECASE).values, 'revenue'] = 1.303\n",
    "    df.loc[df.publisher.str.match('.*SEGA.*').values, 'revenue'] = 1.153\n",
    "    df.loc[df.publisher.str.match('.*capcom.*', flags=re.IGNORECASE).values, 'revenue'] = 0.7673\n",
    "    df.loc[df.publisher.str.match('.*warner.*', flags=re.IGNORECASE).values, 'revenue'] = 0.7324\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessing_bert = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english','bert1','bert2','bert3','bert4','bert5'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output\n",
    "\n",
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)\n",
    "\n",
    "def integrar_bert_logits(df_in):\n",
    "    df = df_in.copy(deep=True)\n",
    "\n",
    "    embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "    bert_logits = np.concatenate(df['short_description'].apply(embed).to_numpy())  # .reshape(100,3)\n",
    "\n",
    "    df[['bert1','bert2','bert3','bert4','bert5']] = pd.DataFrame(bert_logits, index= df.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "def custom_features(dataframe_in):\n",
    "    df = dataframe_in.copy(deep=True)\n",
    "\n",
    "    df['month'] = pd.to_datetime(df['release_date']).dt.month\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.to_julian_date())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = integrar_bert_logits(df_train)\n",
    "df_train = custom_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns\n",
    "columns = list(columns)\n",
    "columns.remove('rating')\n",
    "columns.remove('estimated_sells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h2o.H2OFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AutoML for 20 base models\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=columns, y='rating', training_frame=hf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_automl = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime','revenue']),\n",
    "        ('unchanged',Nothing(),['english','bert1','bert2','bert3','bert4','bert5','rating','estimated_sells'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed = preprocessing_automl.fit_transform(df_train)\n",
    "hf_train_processed = h2o.H2OFrame(df_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AutoML for 20 base models\n",
    "aml_processed = H2OAutoML(max_models=20, seed=1)\n",
    "aml_processed.train(x=columns, y='rating', training_frame=hf_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb_processed = aml_processed.leaderboard\n",
    "lb_processed.head(rows=lb_processed.nrows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prog_cientifica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f12cc99d524414e3daaca7ff7e8e0997cdecd19277513297c62237218c0d43b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
