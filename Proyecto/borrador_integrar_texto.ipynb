{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrador integración o no de variable con descripción de texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "- tener un pipeline básico para cada una de las tareas\n",
    "- dijar pre-procesamiento\n",
    "- compatibilidad con output de modelo de lenguaje\n",
    "- elegir mejor manera de incluir modelo de lenguaje"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columnas con categorías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CategoriesTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return doc.split(';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versión de vectorizador es para columnas con pocas categorías posibles (<1k):\n",
    "- platforms (3 valores posibles)\n",
    "- categories (29 valores posibles)\n",
    "- genres (26 valores posibles)\n",
    "- tags (306 valores posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_some_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 0.05  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5%, 10%, 15%] ???\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta otra versión es para developers y publishers (5617 y 3961 valores posibles respectivamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_many_values = CountVectorizer(\n",
    "    tokenizer = CategoriesTokenizer(),\n",
    "    max_df = 1.0,\n",
    "    min_df = 1  # hiperparametro a optimizar\n",
    "    # valores para GridSearch : [5, 10, 15] ???\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable de fecha de publicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def custom_features(dataframe_in):\n",
    "    df = dataframe_in.copy(deep=True)\n",
    "\n",
    "    df['month'] = pd.to_datetime(df['release_date']).dt.month\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.to_julian_date())\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juntando todo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "\n",
    "\n",
    "preprocesisng = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['month']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price','release_date']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = pd.read_pickle('train.pickle')\n",
    "df_train = custom_features(df_train)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_train, df_train['rating'], test_size=0.3, random_state=0, stratify=df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time_ns()\n",
    "    s = now - since\n",
    "    return s*10**(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP\n",
      "Time elapsed for training: 7.887833531 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 0.041340058000000006 seconds\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.28      0.29      0.28       497\n",
      "Mostly Positive       0.24      0.16      0.19       512\n",
      "       Negative       0.42      0.39      0.40       387\n",
      "       Positive       0.31      0.42      0.36       610\n",
      "  Very Positive       0.39      0.37      0.38       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.33      0.32      0.32      2365\n",
      "   weighted avg       0.32      0.32      0.32      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Resultados clasificación MLP\")\n",
    "start = time.time_ns()\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregando embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"distilbert-videogame-descriptions-rating\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def sentence_clf_output(text):\n",
    "    \"\"\"retorna el SequenceClassifierOutput\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input, return_dict=True, output_hidden_states=True)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_embedding(clf_output):\n",
    "    # retorna el vector de scores de clasificacion (antes de la capa softmax)\n",
    "    return clf_output['logits'][0].detach().numpy().reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LogitsEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: logits_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_logits = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',LogitsEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_logits = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_logits),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con logit embeddings\n",
      "\n",
      "Time elapsed for training: 124.59128301000001 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 51.775721214 seconds\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.24      0.26       497\n",
      "Mostly Positive       0.26      0.29      0.28       512\n",
      "       Negative       0.40      0.41      0.41       387\n",
      "       Positive       0.35      0.46      0.39       610\n",
      "  Very Positive       0.47      0.24      0.32       359\n",
      "\n",
      "       accuracy                           0.33      2365\n",
      "      macro avg       0.35      0.33      0.33      2365\n",
      "   weighted avg       0.34      0.33      0.33      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con logit embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_logits.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_logits.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))\n",
    "\n",
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión token [CLF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_tok_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente al token contextualizado\n",
    "    return cfl_output['hidden_states'][-1][0][0].detach().numpy().reshape(1,768)\n",
    "\n",
    "class CLFTokenEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: first_tok_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_CLFToken = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',CLFTokenEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_CLFToken = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_CLFToken),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultados clasificación MLP con CLFToken embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_CLFToken.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_CLFToken.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 min approx entre fit y predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.26      0.27       497\n",
      "Mostly Positive       0.25      0.20      0.22       512\n",
      "       Negative       0.41      0.40      0.40       387\n",
      "       Positive       0.33      0.43      0.37       610\n",
      "  Very Positive       0.36      0.33      0.34       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.33      0.32      0.32      2365\n",
      "   weighted avg       0.32      0.32      0.32      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión promedio de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_embedding(cfl_output):\n",
    "    # retorna un numpy array correspondiente a la suma de los vectores contextualizados\n",
    "    return cfl_output['hidden_states'][-1][0].detach().numpy().mean(axis=0).reshape(1,768)\n",
    "\n",
    "class MeanEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        embed = lambda row: mean_embedding(sentence_clf_output(row))\n",
    "        X_new = X.apply(embed)\n",
    "        X_new = np.concatenate(X_new.values)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_mean = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('LogitsText',MeanEmbedding(),'short_description')\n",
    "])\n",
    "\n",
    "pipe_mean = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_mean),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con mean embeddings\n",
      "\n",
      "Time elapsed for training: 138.760135343 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 53.925199555000006 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con mean embeddings\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_mean.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_mean.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.35      0.32       497\n",
      "Mostly Positive       0.24      0.13      0.17       512\n",
      "       Negative       0.43      0.34      0.38       387\n",
      "       Positive       0.32      0.50      0.39       610\n",
      "  Very Positive       0.40      0.25      0.31       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.34      0.31      0.31      2365\n",
      "   weighted avg       0.33      0.32      0.31      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "\n",
    "bow = CountVectorizer(\n",
    "    tokenizer= StemmerTokenizer(),\n",
    "    ngram_range=(1,2),\n",
    "    min_df = 0.05, max_df = 0.85\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesisng_bow = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('BoC-plat',boc_some_values,'platforms'),\n",
    "        ('BoC-cat',boc_some_values,'categories'),\n",
    "        ('BoC-genres',boc_some_values,'genres'),\n",
    "        ('BoC-tags',boc_some_values,'tags'),\n",
    "\n",
    "        ('BoC-dev',boc_many_values,'developer'),\n",
    "        ('BoC-pub',boc_many_values,'publisher'),\n",
    "\n",
    "        # ('OneHotEncoder',OneHotEncoder(handle_unknown='ignore'),['...']),\n",
    "        # ('StandardScaler',StandardScaler(), ['...']),\n",
    "        ('MinMaxScaler',MinMaxScaler(),['required_age','price']),\n",
    "        ('BoxCox',PowerTransformer(method='yeo-johnson'),['achievements','average_playtime']),\n",
    "        # ('unchanged',None,['english'])  # chequear como no hacer nada\n",
    "\n",
    "        ('BoWText',bow,'short_description')\n",
    "])\n",
    "\n",
    "pipe_bow = Pipeline([\n",
    "    ('Pre-procesamiento',preprocesisng_bow),\n",
    "    ('Clasificador',MLPClassifier(early_stopping =True,max_iter = 100, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados clasificación MLP con bag-of-words\n",
      "\n",
      "Time elapsed for training: 8.321603699 seconds\n",
      "\n",
      "Time elapsed for inference (eval set): 1.5924704680000001 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados clasificación MLP con bag-of-words\\n\")\n",
    "\n",
    "start = time.time_ns()\n",
    "pipe_bow.fit(X_train, y_train)\n",
    "print(\"Time elapsed for training: {} seconds\\n\".format(timeSince(start)))\n",
    "start = time.time_ns()\n",
    "y_pred = pipe_bow.predict(X_eval)\n",
    "print(\"Time elapsed for inference (eval set): {} seconds\\n\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.29      0.36      0.32       497\n",
      "Mostly Positive       0.23      0.18      0.20       512\n",
      "       Negative       0.39      0.37      0.38       387\n",
      "       Positive       0.35      0.36      0.36       610\n",
      "  Very Positive       0.36      0.37      0.37       359\n",
      "\n",
      "       accuracy                           0.32      2365\n",
      "      macro avg       0.32      0.33      0.32      2365\n",
      "   weighted avg       0.32      0.32      0.32      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prog_cientifica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f12cc99d524414e3daaca7ff7e8e0997cdecd19277513297c62237218c0d43b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
